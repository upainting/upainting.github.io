<!DOCTYPE HTML>
<html>
<head>
<meta charset="utf-8">
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<title>UPainting project page</title>
<meta id="viewport" name="viewport" content="width=500" />
<meta name="description" content="UPainting is a unified text-to-image diffusion model" />


<link rel="stylesheet" href="./theme/css/normalize.css" type="text/css" /> 
<link rel="stylesheet" href="./theme/css/base.css" type="text/css" /> 
<link rel="stylesheet" href="./theme/css/code.css" type="text/css" />

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110992267-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110992267-1');
</script>

<!-- 
<link rel="icon" type="image/png" href="./theme/images/avatar.png" sizes="200x200">
<link rel="icon" type="image/png" href="./theme/images/favicon.png" sizes="32x32"> -->
</head>

<body>

<div class="content">

    <header>
        <h1><a href="https://arxiv.org/pdf/2210.16031.pdf">UPainting: Unified Text-to-Image Diffusion Generation with Cross-modal Guidance</a></h1>
        <img src="./theme/images/leading_samples.png" alt="me">
        <a>Figure 1. Samples generated by UPaintint for both simple and complex scenes. UPainting has a general image generation capability, which can effectively generate simple scene images as well as complex scene images.</a>
        <ul>
            <!--<li><a href="./#pubs">Publications</a></li>
            <li><a href="./#projects">Projects</a></li>
            <li><a href="./#backgroud">Backgroud</a></li>
            <li><a href="./resume.pdf">CV</a></li>
            <li><a href="mailto:cs-ly@pku.edu.cn"</a>Contact</li> -->
        </ul>
    </header>


<!--section id="news">
    <h3>News:</h3>
    <ul>
    <li>[2022.11.02] UniBench is publicly released at: <a href=""> UniBench </a></h4></li>
</ul>
</section-->

<section id="UPainting">
    <header>
    <img src="./theme/images/UPainting.png" alt="UPainting">
    <a>Figure 2. Illustration of the architecture of UPainting, which incorporates cross-modal matching models with a text-conditional diffusion model. </a>
    </header>
    
    <br> Diffusion generative models have recently greatly improved the power of text-conditioned image generation. Existing image generation models mainly include text conditional diffusion model and cross-modal guided diffusion model, which are good at small scene image generation and complex scene image generation respectively. In this work, we propose a simple yet effective approach, namely UPainting, to unify simple and complex scene image generation, as shown in Figure 1. Based on architecture improvements and diverse guidance schedules, UPainting effectively integrates cross-modal guidance from a pretrained image-text matching model into a text conditional diffusion model that utilizes a pretrained Transformer language model as the text encoder. Our key findings is that combining the power of large-scale Transformer language model in understanding language and image-text matching model in capturing cross-modal semantics and style, is effective to improve sample fidelity and image-text alignment of image generation. In this way, UPainting has a more general image generation capability, which can generate images of both simple and complex scenes more effectively. To comprehensively compare text-to-image models, we further create a more general benchmark, UniBench, with well-written Chinese and English prompts in both simple and complex scenes. We compare UPainting with recent models and find that UPainting greatly outperforms other models in terms of caption similarity and image fidelity in both simple and complex scenes.

</section>


<section id="pub">
    <h2>Publications:</h2>
    <ul>
        <li> <b>[Arxiv 2022]</b> <a href="https://weili-nlp.github.io/">Wei Li</a>, Xue Xu, Xinyan Xiao, Jiachen Liu, Hu Yang, Guohao Li, Zhanpeng Wang, Zhifan Feng, Qiaoqiao She, Yajuan Lyu, Hua Wu. <i>UPainting: Unified Text-to-Image Diffusion Generation with Cross-modal Guidance.</i> [<a href="https://arxiv.org/pdf/2210.16031.pdf">PDF</a>] [<a href="https://upainting.github.io/">code</a>]
        </li>
</ul>
</section>
</div>

<section id="UPainting">
    <header>
    <img src="./theme/images/more_samples.png" alt="UPainting">
    <a>Figure 3. More samples generated by UPainting for both simple and complex scenes.</a>
    </header>
</section>


</body>
</html>
